{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Из [статьи](https://www.researchgate.net/publication/332242485_Angular_Softmax_Loss_for_End-to-end_Speaker_Verification) \"angular softmax speaker verification\" и еще [одной статьи](https://deepai.org/publication/deep-speaker-embeddings-for-far-field-speaker-recognition-on-short-utterances) \"Deep Speaker Embeddings for Speaker Recognition\" взяты параметры для достижения цели этого проекта:\n",
    "    features: MFFC - n_mel = 23, frame_length = 25ms, duration treck = 3s.\n",
    "    loss: AMSoftmax(s=3,m-0.35), ArcFace loss, ASoftmax(m = 3)\n",
    "    backend: cosine similarity\n",
    "\n",
    "Use layer TimeDistributed from [article](https://ru-keras.com/wrappers-sloi/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#libs\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from loss_layers import AMSoftmax, ArcFace\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "from sklearn.model_selection import train_test_split\n",
    "from DataGen import DataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Conv1D, Conv2D, LSTM, Dropout,LeakyReLU, PReLU, Reshape, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import MaxPooling1D, MaxPooling2D, Flatten, concatenate, GlobalAveragePooling1D, AveragePooling1D, Lambda, PReLU, GRU\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers, initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def amsoftmax_loss(y_true, y_pred):\n",
    "    scale=30.0\n",
    "    margin=0.25\n",
    "\n",
    "    label = tf.reshape(tf.argmax(y_true, axis=-1), shape=(-1,1))\n",
    "    label = tf.cast(label, dtype=tf.int32) # y\n",
    "    batch_range = tf.reshape(tf.range(tf.shape(y_pred)[0]),shape=(-1,1)) # 0~batchsize-1\n",
    "    indices_of_groundtruth = tf.concat([batch_range, tf.reshape(label,shape=(-1,1))], axis=1) # 2columns vector, 0~batchsize-1 and label\n",
    "    groundtruth_score = tf.gather_nd(y_pred, indices_of_groundtruth) # score of groundtruth\n",
    "\n",
    "    m = tf.constant(margin,name='m')\n",
    "    s = tf.constant(scale,name='s')\n",
    "\n",
    "    added_margin = tf.cast(tf.greater(groundtruth_score,m),dtype=tf.float32)*m # if groundtruth_score>m, groundtruth_score-m\n",
    "    added_margin = tf.reshape(added_margin,shape=(-1,1))\n",
    "    added_embeddingFeature = tf.subtract(y_pred, y_true*added_margin)*s # s(cos_theta_yi-m), s(cos_theta_j)\n",
    "\n",
    "    cross_ent = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=added_embeddingFeature)\n",
    "    loss = tf.reduce_mean(cross_ent)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37776 9445\n"
     ]
    }
   ],
   "source": [
    "path = Path('C:\\\\datasets_from_D\\\\train_vox2_2half\\\\wav_vad\\\\0\\\\')\n",
    "all_audio = natsorted(list(path.rglob('*.wav')))\n",
    "# print(audio[:150])\n",
    "train_audio, test_audio = train_test_split(all_audio, test_size=0.2, random_state=42, shuffle=True)\n",
    "print(len(train_audio), len(test_audio))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepaire generic data for train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# data = DataGenerator(train_audio[:20])\n",
    "# d, cl = next(iter(data))\n",
    "# print(d.shape, cl)\n",
    "train_gen = DataGenerator(train_audio)\n",
    "val_gen = DataGenerator(test_audio)\n",
    "print('Lenght train_gen', len(train_gen))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model from article \"angular softmax speaker verification\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 301, 23)]         0         \n",
      "                                                                 \n",
      " Conv_1 (Conv1D)             (None, 297, 23)           2668      \n",
      "                                                                 \n",
      " MP_1 (MaxPooling1D)         (None, 99, 23)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 99, 128)           77824     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 99, 23)           2967      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " BN_1 (BatchNormalization)   (None, 99, 23)            92        \n",
      "                                                                 \n",
      " Conv_2 (Conv1D)             (None, 97, 512)           35840     \n",
      "                                                                 \n",
      " MP_2 (MaxPooling1D)         (None, 32, 512)           0         \n",
      "                                                                 \n",
      " BN_2 (BatchNormalization)   (None, 32, 512)           2048      \n",
      "                                                                 \n",
      " Conv_3 (Conv1D)             (None, 30, 512)           786944    \n",
      "                                                                 \n",
      " MP_3 (MaxPooling1D)         (None, 10, 512)           0         \n",
      "                                                                 \n",
      " BN_3 (BatchNormalization)   (None, 10, 512)           2048      \n",
      "                                                                 \n",
      " Conv_4 (Conv1D)             (None, 10, 512)           262656    \n",
      "                                                                 \n",
      " MP_4 (MaxPooling1D)         (None, 3, 512)            0         \n",
      "                                                                 \n",
      " BN_4 (BatchNormalization)   (None, 3, 512)            2048      \n",
      "                                                                 \n",
      " Conv_5 (Conv1D)             (None, 3, 1500)           769500    \n",
      "                                                                 \n",
      " BN_5 (BatchNormalization)   (None, 3, 1500)           6000      \n",
      "                                                                 \n",
      " AVGP (AveragePooling1D)     (None, 1, 1500)           0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 1, 256)            1350144   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1, 256)           1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 256)               394752    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " p_re_lu (PReLU)             (None, 256)               256       \n",
      "                                                                 \n",
      " Drop_1 (Dropout)            (None, 256)               0         \n",
      "                                                                 \n",
      " D_1 (Dense)                 (None, 3000)              771000    \n",
      "                                                                 \n",
      " BN_6 (BatchNormalization)   (None, 3000)              12000     \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 3000)              0         \n",
      "                                                                 \n",
      " embed (Dense)               (None, 300)               900300    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              301000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,682,135\n",
      "Trainable params: 5,668,993\n",
      "Non-trainable params: 13,142\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Если не  с работает: 1 -  применить рекурентные слои, 2 - применить Conv2D, 3 - изменить Amsoftmax layer на Arclayer, 4- Применить amsoftmax loss а не слой.\n",
    "from tensorflow.keras import regularizers\n",
    "def create(input_shape=(301, 23)):\n",
    "    input_1 = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    x = Conv1D(23, kernel_size=5, activation='relu', name='Conv_1')(input_1)\n",
    "    x = MaxPooling1D(pool_size=3, name='MP_1')(x)\n",
    "    # x = Conv1D(128, kernel_size=3, activation='relu')(x) kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    "    #\n",
    "    # x = Conv1D(256, kernel_size=3, activation='relu')(x)\n",
    "    # x = LSTM(128, return_sequences=True)(x)\n",
    "    x = TimeDistributed(Dense(23, activation='relu', name=\"TD_1\"))(x)\n",
    "    x = BatchNormalization(momentum=0.99, name='BN_1')(x)\n",
    "\n",
    "    x = Conv1D(512, 3, activation='relu', name='Conv_2')(x)\n",
    "    x = MaxPooling1D(pool_size=3, name='MP_2')(x)\n",
    "    #x = TimeDistributed(Dense(512, activation='relu', name=\"TD_2\"))(x)\n",
    "    x = BatchNormalization(momentum=0.95, name='BN_2')(x)\n",
    "\n",
    "    x = Conv1D(512, 3, activation='relu', name='Conv_3')(x)\n",
    "    x = MaxPooling1D(pool_size=3, name='MP_3')(x)\n",
    "    #x = TimeDistributed(Dense(512, activation='relu', name=\"TD_3\"))(x)\n",
    "    x = BatchNormalization(momentum=0.99, name='BN_3')(x)\n",
    "\n",
    "    x = Conv1D(512, 1, activation='relu', name='Conv_4')(x)\n",
    "    x = MaxPooling1D(pool_size=3, name='MP_4')(x)\n",
    "    #x = TimeDistributed(Dense(512, activation='relu', name=\"TD_4\"))(x)\n",
    "    x = BatchNormalization(momentum=0.95, name='BN_4')(x)\n",
    "\n",
    "    x = Conv1D(1500, 1, activation='relu', name='Conv_5')(x)\n",
    "    # x = TimeDistributed(Dense(1500, activation='relu', name=\"TD_5\"))(x)\n",
    "    x = BatchNormalization(momentum=0.99, name='BN_5')(x)\n",
    "\n",
    "    x = AveragePooling1D(name='AVGP')(x)\n",
    "\n",
    "    x = GRU(256,recurrent_activation=None,return_sequences=True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GRU(256,recurrent_activation=None,return_sequences=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    # Classification block\n",
    "    # x = Flatten(name='Flt')(x)\n",
    "    x = Dropout(0.5, name='Drop_1')(x)\n",
    "    x = Dense(3000, activation='relu', name='D_1')(x)\n",
    "    x = BatchNormalization(momentum=0.95, name='BN_6')(x)\n",
    "    # x = Dense(512, activation='relu', use_bias=False, name='D_2')(x)\n",
    "    # x = BatchNormalization(momentum=0.95, name='BN_7')(x)\n",
    "    x = Lambda(lambda c: K.l2_normalize(c, axis=-1))(x)\n",
    "    embed = Dense(300, activation='relu', name='embed')(x)\n",
    "    outputs = Dense(1000, activation='softmax')(embed)  #  AMSoftmax(1000, s=35, m=0.63, name='AMSoftmax')(embed)    Dense(1000, activation='softmax')(embed)\n",
    "\n",
    "    out_model = Model(input_1, outputs)\n",
    "    out_model.compile(loss=amsoftmax_loss, optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "\n",
    "    return out_model\n",
    "\n",
    "model = create()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#Example TimeDistribute\n",
    "# inputs = tf.keras.Input(shape=(10, 128, 128, 3))\n",
    "# conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3))\n",
    "# outputs = tf.keras.layers.TimeDistributed(conv_2d_layer)(inputs)\n",
    "# outputs.shape\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Callbaxk**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "sv_mod = ModelCheckpoint(\n",
    "    filepath = 'D:\\\\Andrey\\\\data\\\\weights\\\\ARC_mffc_img\\\\\\\n",
    "model_TDL\\\\modelTD_b128_301_23_0f_ohe_{epoch:02d}-loss-{loss:.4f}_val_los-{val_loss:.4f}.hdf5',\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'min',\n",
    "    save_best_only = True\n",
    ")\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                            patience=6,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.9,\n",
    "                                            min_lr=0.00001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**train**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2276/2276 [==============================] - 619s 266ms/step - loss: 6.5592 - accuracy: 0.0060 - val_loss: 6.5092 - val_accuracy: 0.0040 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "2276/2276 [==============================] - 604s 265ms/step - loss: 6.4202 - accuracy: 0.0083 - val_loss: 6.4378 - val_accuracy: 0.0066 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "2276/2276 [==============================] - 602s 265ms/step - loss: 6.3952 - accuracy: 0.0095 - val_loss: 6.4426 - val_accuracy: 0.0067 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "2276/2276 [==============================] - 603s 265ms/step - loss: 6.3674 - accuracy: 0.0108 - val_loss: 6.4263 - val_accuracy: 0.0071 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "2276/2276 [==============================] - 604s 265ms/step - loss: 6.3478 - accuracy: 0.0115 - val_loss: 6.4323 - val_accuracy: 0.0071 - lr: 0.0100\n",
      "Epoch 6/100\n",
      " 742/2276 [========>.....................] - ETA: 5:31 - loss: 6.3286 - accuracy: 0.0129"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen,\n",
    "              epochs = 100,\n",
    "              validation_data = (val_gen),\n",
    "              callbacks = [sv_mod, learning_rate_reduction],\n",
    "              verbose = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#  model.save('D:\\Andrey\\data\\weights\\ARC_mffc_img\\model_TDL\\Model_weights.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#model.load_weights('D:\\Andrey\\data\\weights\\ARC_mffc_img\\model_TDL\\Model_weights.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
